{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f91671-6e4f-4d50-8e64-ac023ebb9df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T16:31:25.440238Z",
     "iopub.status.busy": "2024-09-10T16:31:25.437851Z",
     "iopub.status.idle": "2024-09-10T16:31:25.457925Z",
     "shell.execute_reply": "2024-09-10T16:31:25.457398Z",
     "shell.execute_reply.started": "2024-09-10T16:31:25.440173Z"
    }
   },
   "source": [
    "# 001-Introduction-to-Onboarding-Tuning-Data\n",
    "\n",
    "Download [001-Introduction-to-Onboarding-Tuning-Data.ipynb](001-Introduction-to-Onboarding-Tuning-Data.ipynb) notebook and try it out\n",
    "\n",
    "## Introduction\n",
    "This notebook is intended to be a guide to onboarding a new fine-tuning dataset Geospatial Studio using the python SDK.\n",
    "\n",
    "For more information about the Geospatial Studio see the docs page: [Geospatial Studio Docs](https://terrastackai.github.io/geospatial-studio)\n",
    "\n",
    "For more information about the Geospatial Studio SDK and all the functions available through it, see the SDK docs page: [Geospatial Studio SDK Docs](https://terrastackai.github.io/geospatial-studio-toolkit)\n",
    "\n",
    "## Prerequisites\n",
    "1. Access to a deploy instance of the Geospatial Studio.\n",
    "1. Ability to run and edit a copy of this notebook.\n",
    "1. A sample dataset you want to onboard\n",
    "\n",
    "# Install SDK:\n",
    "\n",
    "1. Prepare a python 3.9+ environment, however you normally do that (e.g. conda, pyenv, poetry, etc.) and activate this new environment.\n",
    "\n",
    "1. Install Jupyter into that environment: `python -m pip install --upgrade pip` then `pip install notebook`\n",
    "\n",
    "1. Install the SDK with: `python -m pip install geostudio`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ed002",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4773e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required packages\n",
    "import urllib3\n",
    "import json\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "from geostudio import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f74c031",
   "metadata": {},
   "source": [
    "## Connecting to the platform\n",
    "\n",
    "First, we set up the connection to the platform backend.  To do this we need the base url for the studio UI and an API key.\n",
    "\n",
    "To get an API Key:\n",
    "1. Go to the Geospatial Studio UI page and navigate to the Manage your API keys link.\n",
    "2.  This should pop-up a window where you can generate, access and delete your api keys. NB: every user is limited to a maximum of two activate api keys at any one time.\n",
    "\n",
    "Store the API key and geostudio ui base url in a credentials file locally, for example in /User/bob/.geostudio_config_file. You can do this by:\n",
    "\n",
    "```bash\n",
    "echo \"GEOSTUDIO_API_KEY=<paste_api_key_here>\" > .geostudio_config_file\n",
    "echo \"BASE_STUDIO_UI_URL=<paste_ui_base_url_here>\" >> .geostudio_config_file\n",
    "```\n",
    "\n",
    "Copy and paste the file path to this credentials file in call below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Initialize Geostudio client using a geostudio config file\n",
    "#############################################################\n",
    "gfm_client = Client(geostudio_config_file=\".geostudio_config_file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a1a68-04f4-4b84-b4e5-dbfebaeb5635",
   "metadata": {},
   "source": [
    "## List and explore existing datasets in the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316a21e-c9b6-4b0f-8c59-7a590407bfab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gfm_client.list_datasets(output=\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbd6c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste the dataset_id of the dataset you want to explore\n",
    "gfm_client.get_dataset(\"geodata-dtxfvhqh2poaylszpfigfd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67c4fb",
   "metadata": {},
   "source": [
    "## Onboard a new Dataset\n",
    "\n",
    "In order to onboard your dataset to the Geospatial Studio, you need to have a direct download URL pointing to a zip file of the dataset. You can use [this dataset url](https://s3.us-east.cloud-object-storage.appdomain.cloud/geospatial-studio-example-data/sen1floods11_v1.1.tar.gz) as an example to go through this notebook.\n",
    "\n",
    "If you have the dataset locally, you can use Box, OneDrive or any other cloud storage you are used to.\n",
    "\n",
    "Optionally, you can upload your data to a temporary location in the cloud (with in Studio object storage) and get a url which can be used to pass to the onboarding process. (*NB: the same upload function can be useful for pushing files for inferecnce or to processing pipelines.*)\n",
    "\n",
    "The dataset needs to packaged as a zip file.\n",
    "\n",
    "*Optional:* zip data files for upload:\n",
    "\n",
    "`zip -j flooding-dataset-upload.zip /Downloads/flooding-dataset-upload/*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2abbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) If you wish to upload the data archive through the studio, you can uncomment and use this function and paste the path to your zipped dataset. \n",
    "uploaded_links = gfm_client.upload_file('/Users/beldinemoturi/Downloads/flood-dataset-test.zip')\n",
    "uploaded_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72499a5e",
   "metadata": {},
   "source": [
    "<!-- You can use the function below to pre-scan your dataset and do some basic sanity checks. This will (if possible) check that you have matching data and label pairs based on filenames, and check that you have specified the correct number of bands -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa923ea-7a2c-4684-928a-9c1d0d4d7d92",
   "metadata": {},
   "source": [
    "### Onboard the dataset to the dataset factory\n",
    "\n",
    "Now we provide information about the dataset, including name, description, data and label file suffixes, dataset purpose, data sources, etc. Below is an example payload that defines most of the values you will need to onboard a dataset to the Studio. For more information on what you can provide during the onboarding process, check out the SDK Documentation\n",
    "\n",
    "The Geospatial Studio allows users to onboard either multi-modal data or uni-modal data. For the multi-modal data, users shall provide, as a list, a different data source for each input modality of the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ac5a8c",
   "metadata": {},
   "source": [
    "Below are some example data connectors, collections and modality_tags to be provided in the dataset need to be correctly matched. See table below.  (The modality tags relate to the modalities in the Terramind model)\n",
    "\n",
    "| Collections | Modality tag | Connector |\n",
    "| :--- | :---: | ---: |\n",
    "| s2_l1c | S2L1C | sentinelhub |\n",
    "| dem | DEM | sentinelhub |\n",
    "| s1_grd | S1GRD | sentinelhub |\n",
    "| hls_l30 | HLS_L30 | sentinelhub |\n",
    "| hls_s30 | HLS_S30 | sentinelhub |\n",
    "| s2_l2a | S2L2A | sentinelhub |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b001d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-modal data\n",
    "# Edit the details in the dict and dataset_url below to suit your dataset\n",
    "\n",
    "multi_modal_datasetDict = {\n",
    "    \"dataset_name\": \"Sentinel Flood Multimodal Test\",\n",
    "    \"data_sources\": [\n",
    "        {\n",
    "            \"bands\": [\n",
    "                {\n",
    "                    \"index\": \"0\",\n",
    "                    \"band_name\": \"Coastal_aerosol\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"1\",\n",
    "                    \"band_name\": \"Blue\",\n",
    "                    \"RGB_band\": \"B\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"2\",\n",
    "                    \"band_name\": \"Green\",\n",
    "                    \"RGB_band\": \"G\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"3\",\n",
    "                    \"band_name\": \"Red\",\n",
    "                    \"RGB_band\": \"R\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"4\",\n",
    "                    \"band_name\": \"05_-_Vegetation_Red_Edge\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"5\",\n",
    "                    \"band_name\": \"06_-_Vegetation_Red_Edge\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"6\",\n",
    "                    \"band_name\": \"07_-_Vegetation_Red_Edge\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"7\",\n",
    "                    \"band_name\": \"08_-_NIR\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"8\",\n",
    "                    \"band_name\": \"08A_-_Vegetation_Red_Edge\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"9\",\n",
    "                    \"band_name\": \"09_-_Water_vapour\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"10\",\n",
    "                    \"band_name\": \"11_-_SWIR\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"11\",\n",
    "                    \"band_name\": \"12_-_SWIR\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"12\",\n",
    "                    \"band_name\": \"Cloud_Probability\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "            ],\n",
    "            \"connector\": \"sentinelhub\",\n",
    "            \"collection\": \"s2_l2a\",\n",
    "            \"modality_tag\": \"S2L1C\",\n",
    "            \"file_suffix\": \"_S2Hand.tif\"\n",
    "        },\n",
    "        {\n",
    "            \"bands\": [\n",
    "                {\"index\": \"0\", \"band_name\": \"VV (Gray)\", \"description\": \"\"},\n",
    "                {\"index\": \"1\", \"band_name\": \"VH\", \"description\": \"\"},\n",
    "            ],\n",
    "            \"connector\": \"sentinelhub\",\n",
    "            \"collection\": \"s1_grd\",\n",
    "            \"modality_tag\": \"S1GRD\",\n",
    "            \"align_dates\": \"true\",\n",
    "            \"file_suffix\": \"_S1Hand.tif\",\n",
    "            \"scaling_factor\": [1, 1],\n",
    "        },\n",
    "    ],\n",
    "    \"label_categories\": [\n",
    "        {\"id\": \"0\", \"name\": \"No Floods\", \"description\": \"Flooding assets\"},\n",
    "        {\"id\": \"1\", \"name\": \"Floods\", \"description\": \"Flooding assets\"},\n",
    "    ],\n",
    "    \"dataset_url\": uploaded_links[\"download_url\"],\n",
    "    \"description\": \"Flood data from places\",\n",
    "    \"label_suffix\": \"_LabelHand.tif\",\n",
    "    \"purpose\": \"Segmentation\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a1ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimodal data\n",
    "# Edit the details in the dict and dataset_url below to suit your dataset\n",
    "unimodal_datasetDict = {\n",
    "    \"dataset_name\": \"Inria Dataset Buildings dataset\",\n",
    "    \"data_sources\": [\n",
    "        {\n",
    "            \"bands\": [\n",
    "                {\n",
    "                    \"index\": \"0\",\n",
    "                    \"band_name\": \"Red\",\n",
    "                    \"RGB_band\": \"R\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"1\",\n",
    "                    \"band_name\": \"Green\",\n",
    "                    \"RGB_band\": \"G\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"index\": \"2\",\n",
    "                    \"band_name\": \"Blue\",\n",
    "                    \"RGB_band\": \"B\",\n",
    "                    \"description\": \"\",\n",
    "                    \"scaling_factor\": \"1\",\n",
    "                },\n",
    "            ],\n",
    "            \"connector\": \"sentinelhub\",\n",
    "            \"collection\": \"hls_l30\",\n",
    "            \"modality_tag\": \"HLS_L30\",\n",
    "            \"file_suffix\": \"_train.tif\",\n",
    "        }\n",
    "    ],\n",
    "    \"label_categories\": [\n",
    "        {\"id\": \"0\", \"name\": \"No buildings\", \"description\": \"Building assets\"},\n",
    "        {\"id\": \"1\", \"name\": \"Buildings\", \"description\": \"Building assets\"},\n",
    "    ],\n",
    "    \"dataset_url\": uploaded_links[\"download_url\"],\n",
    "    \"description\": \"Inria building labeling dataset\",\n",
    "    \"label_suffix\": \"_label.tif\",\n",
    "    \"purpose\": \"Segmentation\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792109c7",
   "metadata": {},
   "source": [
    "Once we have prepared the dataset onboading payload, we can use the `onboard_dataset` function to \n",
    "onboard the dataset to studio.  This sends the payload to studio backend api and the dataset onboarding\n",
    "process is triggered.  This involves downloading the data, validating it, calculating statistics and \n",
    "metadata, before storing it ready for model tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54347dd0-f0ec-4a9f-acbe-82aa96ff4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the data with the correct dataset payload\n",
    "onboard_response = gfm_client.onboard_dataset(data=unimodal_datasetDict)\n",
    "display(json.dumps(onboard_response, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c96b9",
   "metadata": {},
   "source": [
    "### Monitor onboarding status\n",
    "\n",
    "You can then monitor the status of the onboarding process through the API with the `get_dataset()` function or polling function.  You can alternatively monitor progress and view the dataset in the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poll onboarding status\n",
    "gfm_client.poll_onboard_dataset_until_finished(onboard_response[\"dataset_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0b145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfm_client.get_dataset(dataset_id=onboard_response[\"dataset_id\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
